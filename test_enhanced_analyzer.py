#!/usr/bin/env python3
import sys
sys.path.insert(0, 'video-learning-helper-backend')

from app.video_analyzer import VideoAnalyzer
from pathlib import Path
import json

print('ğŸ”§ æµ‹è¯•å¢å¼ºçš„AIåˆ†æå™¨...')

# åˆ›å»ºåˆ†æå™¨å®ä¾‹
analyzer = VideoAnalyzer()

# æµ‹è¯•è§†é¢‘æ–‡ä»¶
video_file = Path('video-learning-helper-backend/uploads/fc1d7978-5abc-49a4-9efe-1d173637087c.mp4')

if not video_file.exists():
    print(f'âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_file}')
    print('è¯·ç¡®ä¿æœ‰ä¸€ä¸ªå¯ç”¨çš„æµ‹è¯•è§†é¢‘æ–‡ä»¶')
    exit(1)

# é…ç½®æµ‹è¯•ä»»åŠ¡
task_config = {
    "video_segmentation": True,
    "transition_detection": True,
    "audio_transcription": False,  # æš‚æ—¶è·³è¿‡éŸ³é¢‘è½¬å½•ä»¥åŠ å¿«æµ‹è¯•
    "report_generation": False     # æš‚æ—¶è·³è¿‡æŠ¥å‘Šç”Ÿæˆä»¥åŠ å¿«æµ‹è¯•
}

test_task_id = "test_enhanced_analyzer_123"

def progress_callback(progress, message):
    print(f"è¿›åº¦: {progress}% - {message}")

try:
    print(f'ğŸ¬ åˆ†æè§†é¢‘æ–‡ä»¶: {video_file}')
    results = analyzer.analyze_video(
        str(video_file), 
        task_config, 
        progress_callback, 
        test_task_id
    )
    
    print('\nâœ… åˆ†æå®Œæˆ!')
    
    # æ£€æŸ¥åˆ†æ®µç»“æœ
    segments = results.get('segments', [])
    print(f'\nğŸ“Š åˆ†æ®µåˆ†æç»“æœ:')
    print(f'   æ€»åˆ†æ®µæ•°: {len(segments)}')
    
    # æ£€æŸ¥å‰5ä¸ªåˆ†æ®µçš„è¯¦ç»†ä¿¡æ¯
    for i, segment in enumerate(segments[:5]):
        print(f'\n   åˆ†æ®µ {segment["segment_id"]}:')
        print(f'     æ—¶é•¿: {segment["duration"]:.2f}s')
        print(f'     åœºæ™¯ç±»å‹: {segment["scene_type"]}')
        print(f'     ç¼©ç•¥å›¾: {segment.get("thumbnail_url", "âŒ æ— ")}')
        print(f'     GIF: {segment.get("gif_url", "âŒ æ— ")}')
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if segment.get('thumbnail_url'):
            thumbnail_file = Path(f'video-learning-helper-backend{segment["thumbnail_url"]}')
            print(f'     ç¼©ç•¥å›¾æ–‡ä»¶å­˜åœ¨: {"âœ…" if thumbnail_file.exists() else "âŒ"} {thumbnail_file.name}')
        
        if segment.get('gif_url'):
            gif_file = Path(f'video-learning-helper-backend{segment["gif_url"]}')
            print(f'     GIFæ–‡ä»¶å­˜åœ¨: {"âœ…" if gif_file.exists() else "âŒ"} {gif_file.name}')
    
    if len(segments) > 5:
        print(f'   ... è¿˜æœ‰ {len(segments) - 5} ä¸ªåˆ†æ®µ')
    
    # æ£€æŸ¥è½¬åœºç»“æœ
    transitions = results.get('transitions', [])
    print(f'\nğŸï¸  è½¬åœºæ£€æµ‹ç»“æœ:')
    print(f'   æ€»è½¬åœºæ•°: {len(transitions)}')
    
    for i, transition in enumerate(transitions[:10]):
        print(f'   è½¬åœº {transition["transition_id"]}: {transition["timestamp"]:.2f}s, å¼ºåº¦: {transition["strength"]:.3f}, ç±»å‹: {transition["type"]}')
    
    if len(transitions) > 10:
        print(f'   ... è¿˜æœ‰ {len(transitions) - 10} ä¸ªè½¬åœº')
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    results_file = Path(f'video-learning-helper-backend/uploads/{test_task_id}_results.json')
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)
    
    print(f'\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜: {results_file}')
    
    # ç»Ÿè®¡ç¼©ç•¥å›¾å’ŒGIFæ–‡ä»¶
    uploads_dir = Path('video-learning-helper-backend/uploads')
    thumbnail_files = list(uploads_dir.glob(f'{test_task_id}_segment_*_thumbnail.jpg'))
    gif_files = list(uploads_dir.glob(f'{test_task_id}_segment_*.gif'))
    
    print(f'\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:')
    print(f'   ç¼©ç•¥å›¾æ–‡ä»¶: {len(thumbnail_files)} ä¸ª')
    print(f'   GIFæ–‡ä»¶: {len(gif_files)} ä¸ª')
    
    # è®¡ç®—è´¨é‡åˆ†æ•°
    total_segments = len(segments)
    segments_with_thumbnails = sum(1 for s in segments if s.get('thumbnail_url'))
    segments_with_gifs = sum(1 for s in segments if s.get('gif_url'))
    
    quality_score = 0
    if total_segments > 0:
        # åŸºç¡€åˆ†æ•°ï¼šæœ‰åˆ†æ®µ
        quality_score += 40
        
        # è½¬åœºæ£€æµ‹åˆ†æ•°
        expected_transitions = max(total_segments // 3, 5)  # é¢„æœŸè½¬åœºæ•°
        transition_score = min(len(transitions) / expected_transitions, 1.0) * 30
        quality_score += transition_score
        
        # ç¼©ç•¥å›¾åˆ†æ•°
        thumbnail_score = (segments_with_thumbnails / total_segments) * 15
        quality_score += thumbnail_score
        
        # GIFåˆ†æ•°
        gif_score = (segments_with_gifs / total_segments) * 15
        quality_score += gif_score
    
    print(f'\nğŸ“ˆ æ•°æ®è´¨é‡è¯„ä¼°:')
    print(f'   æ€»ä½“è´¨é‡åˆ†æ•°: {quality_score:.1f}%')
    print(f'   åˆ†æ®µå®Œæ•´æ€§: {len(segments) > 0}')
    print(f'   è½¬åœºæ£€æµ‹ç‡: {len(transitions)}/{expected_transitions} (æœŸæœ›)')
    print(f'   ç¼©ç•¥å›¾è¦†ç›–ç‡: {segments_with_thumbnails}/{total_segments} ({segments_with_thumbnails/total_segments*100:.1f}%)')
    print(f'   GIFè¦†ç›–ç‡: {segments_with_gifs}/{total_segments} ({segments_with_gifs/total_segments*100:.1f}%)')
    
    if quality_score >= 90:
        print('ğŸ‰ ä¼˜ç§€ï¼æ•°æ®è´¨é‡å¾ˆé«˜')
    elif quality_score >= 75:
        print('ğŸ‘ è‰¯å¥½ï¼æ•°æ®è´¨é‡å¯æ¥å—')
    else:
        print('âš ï¸  éœ€è¦æ”¹è¿›æ•°æ®è´¨é‡')

except Exception as e:
    print(f'âŒ æµ‹è¯•å¤±è´¥: {e}')
    import traceback
    traceback.print_exc() 