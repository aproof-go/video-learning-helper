"""
ç¯å¢ƒé…ç½®ç®¡ç†
æ”¯æŒæµ‹è¯•ã€ç”Ÿäº§ç¯å¢ƒçš„æ•°æ®åº“å’Œå­˜å‚¨åˆ†ç¦»
"""

import os
from pathlib import Path
from typing import Optional, Literal
from pydantic import BaseSettings, Field
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv("config.env")

Environment = Literal["development", "production"]

class Settings(BaseSettings):
    """åº”ç”¨è®¾ç½®"""
    
    # ç¯å¢ƒé…ç½®
    node_env: Environment = Field(default="development", env="NODE_ENV")
    debug: bool = Field(default=True, env="DEBUG")
    
    # æœåŠ¡å™¨é…ç½®
    host: str = Field(default="0.0.0.0", env="HOST")
    port: int = Field(default=8000, env="PORT")
    reload: bool = Field(default=True, env="RELOAD")
    
    # JWTé…ç½®
    secret_key: str = Field(env="SECRET_KEY")
    algorithm: str = Field(default="HS256", env="ALGORITHM")
    access_token_expire_minutes: int = Field(default=30, env="ACCESS_TOKEN_EXPIRE_MINUTES")
    
    # æ–‡ä»¶ä¸Šä¼ é…ç½®
    upload_dir: Path = Field(default=Path("uploads"))
    max_file_size: int = Field(default=500 * 1024 * 1024)  # 500MB
    allowed_video_extensions: set = {".mp4", ".avi", ".mov", ".mkv", ".wmv", ".flv"}
    
    # å­˜å‚¨é…ç½®
    storage_provider: Literal["local", "supabase", "aws_s3"] = Field(default="local", env="STORAGE_PROVIDER")
    use_local_storage: bool = Field(default=True, env="USE_LOCAL_STORAGE")
    
    # æµ‹è¯•ç¯å¢ƒæ•°æ®åº“é…ç½®ï¼ˆç°æœ‰é…ç½®ï¼‰
    supabase_url_dev: str = Field(env="SUPABASE_URL_DEV")
    supabase_key_dev: str = Field(env="SUPABASE_KEY_DEV")
    supabase_storage_bucket_dev: str = Field(default="video-learning-test", env="SUPABASE_STORAGE_BUCKET_DEV")
    
    # ç”Ÿäº§ç¯å¢ƒæ•°æ®åº“é…ç½®ï¼ˆap-production é¡¹ç›®ï¼‰
    supabase_url_prod: Optional[str] = Field(default=None, env=["SUPABASE_URL_PROD", "SUPABASE_URL_PRODUCTION"])
    supabase_key_prod: Optional[str] = Field(default=None, env=["SUPABASE_KEY_PROD", "SUPABASE_KEY_PRODUCTION"])
    supabase_storage_bucket_prod: str = Field(default="video-learning-prod", env=["SUPABASE_STORAGE_BUCKET_PROD", "SUPABASE_STORAGE_BUCKET_PRODUCTION"])
    
    # AWS S3 é…ç½®ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
    aws_access_key_id: Optional[str] = Field(default=None, env="AWS_ACCESS_KEY_ID")
    aws_secret_access_key: Optional[str] = Field(default=None, env="AWS_SECRET_ACCESS_KEY")
    aws_region: str = Field(default="us-east-1", env="AWS_REGION")
    aws_s3_bucket_dev: str = Field(default="video-learning-test", env="AWS_S3_BUCKET_DEV")
    aws_s3_bucket_prod: str = Field(default="video-learning-prod", env="AWS_S3_BUCKET_PROD")
    
    # CORSé…ç½®
    cors_origins: list = [
        "http://localhost:3000",
        "http://localhost:3001", 
        "http://localhost:3002",
        "http://localhost:3003",
        "http://127.0.0.1:3000",
        "http://127.0.0.1:3001",
        "http://127.0.0.1:3002",
        "http://127.0.0.1:3003"
    ]
    
    # ä»»åŠ¡å¤„ç†é…ç½®
    max_concurrent_tasks: int = Field(default=2, env="MAX_CONCURRENT_TASKS")
    task_timeout: int = Field(default=3600, env="TASK_TIMEOUT")
    
    # è§†é¢‘åˆ†æé…ç½®
    enable_real_analysis: bool = Field(default=True, env="ENABLE_REAL_ANALYSIS")
    ffmpeg_path: Optional[str] = Field(default=None, env="FFMPEG_PATH")
    
    @property
    def supabase_url(self) -> str:
        """æ ¹æ®ç¯å¢ƒè·å–Supabase URL"""
        if self.node_env == "production":
            if not self.supabase_url_prod:
                raise ValueError("ç”Ÿäº§ç¯å¢ƒå¿…é¡»é…ç½® SUPABASE_URL_PROD")
            return self.supabase_url_prod
        else:
            # æµ‹è¯•ç¯å¢ƒï¼šä½¿ç”¨ç°æœ‰é…ç½®
            return self.supabase_url_dev
    
    @property
    def supabase_key(self) -> str:
        """æ ¹æ®ç¯å¢ƒè·å–Supabase Key"""
        if self.node_env == "production":
            if not self.supabase_key_prod:
                raise ValueError("ç”Ÿäº§ç¯å¢ƒå¿…é¡»é…ç½® SUPABASE_KEY_PROD")
            return self.supabase_key_prod
        else:
            # æµ‹è¯•ç¯å¢ƒï¼šä½¿ç”¨ç°æœ‰é…ç½®
            return self.supabase_key_dev
    
    @property
    def storage_bucket(self) -> str:
        """æ ¹æ®ç¯å¢ƒè·å–å­˜å‚¨æ¡¶åç§°"""
        if self.storage_provider == "supabase":
            if self.node_env == "production":
                return self.supabase_storage_bucket_prod
            else:
                return self.supabase_storage_bucket_dev
        elif self.storage_provider == "aws_s3":
            if self.node_env == "production":
                return self.aws_s3_bucket_prod
            else:
                return self.aws_s3_bucket_dev
        else:
            return "local"
    
    @property
    def is_production(self) -> bool:
        """æ˜¯å¦ä¸ºç”Ÿäº§ç¯å¢ƒ"""
        return self.node_env == "production"
    
    @property
    def is_development(self) -> bool:
        """æ˜¯å¦ä¸ºæµ‹è¯•ç¯å¢ƒï¼ˆåŒ…æ‹¬æœ¬åœ°å¼€å‘ï¼‰"""
        return self.node_env == "development"
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
        self.upload_dir.mkdir(exist_ok=True)
        
        # è¾“å‡ºç¯å¢ƒä¿¡æ¯
        env_name = "ç”Ÿäº§ç¯å¢ƒ" if self.is_production else "æµ‹è¯•ç¯å¢ƒ"
        print(f"ğŸš€ å¯åŠ¨ç¯å¢ƒ: {env_name} ({self.node_env.upper()})")
        print(f"ğŸ—„ï¸ æ•°æ®åº“: {self.supabase_url}")
        print(f"ğŸ“¦ å­˜å‚¨æ–¹å¼: {self.storage_provider}")
        print(f"ğŸª£ å­˜å‚¨æ¡¶: {self.storage_bucket}")
        print(f"ğŸ“ ä¸Šä¼ ç›®å½•: {self.upload_dir.absolute()}")
        
        if self.debug:
            print(f"ğŸ”§ è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")

    class Config:
        env_file = "config.env"
        case_sensitive = False

# å…¨å±€è®¾ç½®å®ä¾‹
settings = Settings()

def get_settings() -> Settings:
    """è·å–é…ç½®å®ä¾‹"""
    return settings 