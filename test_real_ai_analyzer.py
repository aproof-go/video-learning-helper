#!/usr/bin/env python3
"""
æµ‹è¯•çœŸæ­£çš„AIè§†é¢‘åˆ†æå™¨
"""

import sys
import os
from pathlib import Path

# æ·»åŠ backendè·¯å¾„
backend_path = Path(__file__).parent / "video-learning-helper-backend" / "app"
sys.path.append(str(backend_path))

from video_analyzer import VideoAnalyzer

def test_real_ai_analyzer():
    """æµ‹è¯•çœŸæ­£çš„AIè§†é¢‘åˆ†æå™¨"""
    print("ğŸ¤– æµ‹è¯•çœŸæ­£çš„AIè§†é¢‘åˆ†æå™¨...")
    
    # æµ‹è¯•è§†é¢‘è·¯å¾„
    video_path = "/Users/apulu/Desktop/learning/å†™ç»™è‡ªå‘çš„è‡ªå·±çš„ä¸€å°ä¿¡ - 001 - å†™ç»™è‡ªå‘çš„è‡ªå·±çš„ä¸€å°ä¿¡.mp4"
    
    if not Path(video_path).exists():
        print(f"âŒ æµ‹è¯•è§†é¢‘ä¸å­˜åœ¨: {video_path}")
        return
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = VideoAnalyzer()
    
    # æµ‹è¯•ä»»åŠ¡ID
    task_id = "real_ai_test_001"
    
    print(f"ğŸ“¹ åˆ†æè§†é¢‘: {Path(video_path).name}")
    
    try:
        # åªæµ‹è¯•è§†é¢‘åˆ†å‰²åŠŸèƒ½
        task_config = {
            "video_segmentation": True,
            "transition_detection": True,
            "audio_transcription": False,  # æš‚æ—¶è·³è¿‡éŸ³é¢‘åˆ†æ
            "report_generation": False
        }
        
        def progress_callback(progress, message):
            print(f"è¿›åº¦: {progress}% - {message}")
        
        results = analyzer.analyze_video(
            video_path=video_path,
            task_config=task_config,
            progress_callback=progress_callback,
            task_id=task_id
        )
        
        # åˆ†æç»“æœ
        segments = results.get("segments", [])
        transitions = results.get("transitions", [])
        video_info = results.get("video_info", {})
        
        print("\nğŸ“Š åˆ†æç»“æœ:")
        print(f"è§†é¢‘æ—¶é•¿: {video_info.get('duration', 0):.1f} ç§’")
        print(f"å¸§ç‡: {video_info.get('fps', 0):.1f} fps")
        print(f"åˆ†è¾¨ç‡: {video_info.get('width', 0)}x{video_info.get('height', 0)}")
        print(f"ç‰‡æ®µæ•°é‡: {len(segments)}")
        print(f"è½¬åœºæ•°é‡: {len(transitions)}")
        
        print("\nğŸ¬ AIæ™ºèƒ½åˆ†å‰²ç‰‡æ®µè¯¦æƒ…:")
        for segment in segments:
            print(f"ç‰‡æ®µ {segment['segment_id']}: "
                  f"{segment['start_time']:.1f}s - {segment['end_time']:.1f}s "
                  f"({segment['duration']:.1f}s) - {segment.get('scene_type', 'æœªçŸ¥åœºæ™¯')}")
        
        print("\nğŸ”„ è½¬åœºæ£€æµ‹ç»“æœ:")
        for i, transition in enumerate(transitions[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"è½¬åœº {i+1}: {transition['timestamp']:.1f}s "
                  f"(å¼ºåº¦: {transition['strength']:.3f}, ç±»å‹: {transition['type']})")
        if len(transitions) > 10:
            print(f"... è¿˜æœ‰ {len(transitions) - 10} ä¸ªè½¬åœº")
        
        # åˆ†æç»“æœè´¨é‡
        if segments:
            durations = [s['duration'] for s in segments]
            avg_duration = sum(durations) / len(durations)
            min_duration = min(durations)
            max_duration = max(durations)
            
            print(f"\nğŸ“ˆ åˆ†å‰²è´¨é‡åˆ†æ:")
            print(f"å¹³å‡ç‰‡æ®µé•¿åº¦: {avg_duration:.1f} ç§’")
            print(f"æœ€çŸ­ç‰‡æ®µ: {min_duration:.1f} ç§’")
            print(f"æœ€é•¿ç‰‡æ®µ: {max_duration:.1f} ç§’")
            
            # æ£€æŸ¥æ˜¯å¦çœŸæ­£æ™ºèƒ½åˆ†å‰²
            variance = sum((d - avg_duration) ** 2 for d in durations) / len(durations)
            std_dev = variance ** 0.5
            
            if std_dev > 5.0:  # å¦‚æœæ ‡å‡†å·®å¤§äº5ç§’ï¼Œè¯´æ˜æ˜¯å˜é•¿åˆ†å‰²
                print("âœ… æ£€æµ‹åˆ°çœŸæ­£çš„AIæ™ºèƒ½åˆ†å‰²ï¼ç‰‡æ®µé•¿åº¦æœ‰æ˜æ˜¾å˜åŒ–")
            else:
                print("âš ï¸  è­¦å‘Š: ç‰‡æ®µé•¿åº¦å˜åŒ–è¾ƒå°ï¼Œå¯èƒ½ä¸æ˜¯çœŸæ­£çš„æ™ºèƒ½åˆ†å‰²")
        
        print(f"\nğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_real_ai_analyzer() 