#!/usr/bin/env python3
"""
è°ƒè¯•AIåˆ†æå™¨çš„åˆ†å‰²é€»è¾‘
"""

import cv2
import numpy as np
from pathlib import Path
from sklearn.cluster import KMeans
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def debug_video_segmentation():
    """è°ƒè¯•è§†é¢‘åˆ†å‰²ç®—æ³•"""
    video_path = Path("video-learning-helper-backend/uploads/46f6b955-7058-4361-8f83-39ef82fd9000.mp4")
    
    if not video_path.exists():
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return
    
    print("ğŸ” å¼€å§‹è°ƒè¯•è§†é¢‘åˆ†å‰²ç®—æ³•")
    print("=" * 60)
    
    try:
        cap = cv2.VideoCapture(str(video_path))
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = frame_count / fps
        
        print(f"è§†é¢‘ä¿¡æ¯:")
        print(f"  å¸§ç‡: {fps} FPS")
        print(f"  æ€»å¸§æ•°: {frame_count}")
        print(f"  æ—¶é•¿: {duration:.2f} ç§’")
        
        # ç”¨äºå­˜å‚¨å¸§çš„ç‰¹å¾
        frame_features = []
        timestamps = []
        
        # æ¯ç§’é‡‡æ ·ä¸€å¸§è¿›è¡Œåˆ†æ
        sample_interval = max(1, int(fps))
        
        frame_idx = 0
        processed_frames = 0
        
        print(f"\nğŸ¬ å¼€å§‹æå–å¸§ç‰¹å¾ (é‡‡æ ·é—´éš”: {sample_interval})")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            if frame_idx % sample_interval == 0:
                # æå–å¸§ç‰¹å¾ (é¢œè‰²ç›´æ–¹å›¾)
                feature = extract_frame_features(frame)
                frame_features.append(feature)
                timestamps.append(frame_idx / fps)
                
                processed_frames += 1
                if processed_frames % 30 == 0:
                    print(f"  å·²å¤„ç†: {processed_frames} å¸§, æ—¶é—´æˆ³: {timestamps[-1]:.2f}s")
            
            frame_idx += 1
        
        cap.release()
        
        print(f"\nğŸ“Š ç‰¹å¾æå–å®Œæˆ:")
        print(f"  æ€»é‡‡æ ·å¸§æ•°: {len(frame_features)}")
        print(f"  ç‰¹å¾ç»´åº¦: {len(frame_features[0]) if frame_features else 0}")
        print(f"  æ—¶é—´èŒƒå›´: 0 - {timestamps[-1]:.2f}s")
        
        if len(frame_features) < 2:
            print("âŒ é‡‡æ ·å¸§æ•°å¤ªå°‘ï¼Œæ— æ³•è¿›è¡Œåˆ†å‰²")
            return
        
        # ä½¿ç”¨K-meansèšç±»è¿›è¡Œåœºæ™¯åˆ†å‰²
        n_clusters = min(10, len(frame_features) // 5)
        print(f"\nğŸ§  K-meansèšç±»åˆ†æ:")
        print(f"  èšç±»æ•°é‡: {n_clusters}")
        
        if n_clusters > 1:
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            labels = kmeans.fit_predict(frame_features)
            
            print(f"  èšç±»æ ‡ç­¾: {labels[:20]}... (å‰20ä¸ª)")
            print(f"  æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(labels)}")
            
            # æ‰¾åˆ°åœºæ™¯è¾¹ç•Œ
            scene_changes = [0]
            for i in range(1, len(labels)):
                if labels[i] != labels[i-1]:
                    scene_changes.append(i)
            scene_changes.append(len(labels) - 1)
            
            print(f"\nğŸ¯ åœºæ™¯è¾¹ç•Œåˆ†æ:")
            print(f"  åœºæ™¯å˜åŒ–ç‚¹: {scene_changes}")
            print(f"  åœºæ™¯æ•°é‡: {len(scene_changes) - 1}")
            
            # ç”Ÿæˆåˆ†å‰²ç»“æœ
            segments = []
            for i in range(len(scene_changes) - 1):
                start_idx = scene_changes[i]
                end_idx = scene_changes[i + 1]
                
                start_time = timestamps[start_idx]
                end_time = timestamps[end_idx]
                duration = end_time - start_time
                
                segment = {
                    "segment_id": i + 1,
                    "start_time": start_time,
                    "end_time": end_time,
                    "duration": duration,
                    "scene_type": f"åœºæ™¯ {i + 1}",
                    "frame_count": (end_idx - start_idx) * sample_interval
                }
                segments.append(segment)
                
                print(f"  ç‰‡æ®µ{i+1}: {start_time:.2f}s - {end_time:.2f}s (æ—¶é•¿: {duration:.2f}s)")
            
            print(f"\nğŸ“‹ åˆ†å‰²ç»“æœæ€»ç»“:")
            print(f"  æ€»ç‰‡æ®µæ•°: {len(segments)}")
            durations = [s['duration'] for s in segments]
            print(f"  å¹³å‡æ—¶é•¿: {np.mean(durations):.2f}s")
            print(f"  æœ€çŸ­ç‰‡æ®µ: {np.min(durations):.2f}s")
            print(f"  æœ€é•¿ç‰‡æ®µ: {np.max(durations):.2f}s")
            print(f"  æ—¶é•¿æ ‡å‡†å·®: {np.std(durations):.2f}s")
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç‰‡æ®µéƒ½æ˜¯30ç§’
            if all(abs(d - 30.0) < 0.1 for d in durations):
                print("âš ï¸  è­¦å‘Š: æ‰€æœ‰ç‰‡æ®µéƒ½æ˜¯30ç§’ï¼Œè¿™ä¸æ­£å¸¸ï¼")
                print("å¯èƒ½çš„åŸå› :")
                print("  1. é‡‡æ ·é—´éš”å¯¼è‡´æ—¶é—´æˆ³é—´éš”å›ºå®šä¸º30ç§’")
                print("  2. K-meansèšç±»ç®—æ³•æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åœºæ™¯è¾¹ç•Œ") 
                print("  3. è§†é¢‘å†…å®¹è¿‡äºå•ä¸€ï¼Œç¼ºä¹åœºæ™¯å˜åŒ–")
                
                # æ£€æŸ¥æ—¶é—´æˆ³é—´éš”
                if len(timestamps) > 1:
                    time_diffs = [timestamps[i+1] - timestamps[i] for i in range(len(timestamps)-1)]
                    print(f"\n  æ—¶é—´æˆ³é—´éš”åˆ†æ:")
                    print(f"    é—´éš”èŒƒå›´: {min(time_diffs):.2f}s - {max(time_diffs):.2f}s")
                    print(f"    å¹³å‡é—´éš”: {np.mean(time_diffs):.2f}s")
                    print(f"    æ˜¯å¦å›ºå®šé—´éš”: {len(set([round(d, 1) for d in time_diffs])) == 1}")
            
        else:
            print("âŒ æ— æ³•è¿›è¡Œèšç±»åˆ†æ")
            
    except Exception as e:
        logger.error(f"è°ƒè¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def extract_frame_features(frame) -> np.ndarray:
    """æå–å¸§ç‰¹å¾ - ä¸AIåˆ†æå™¨ç›¸åŒçš„é€»è¾‘"""
    # è½¬æ¢åˆ°HSVé¢œè‰²ç©ºé—´
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    
    # è®¡ç®—é¢œè‰²ç›´æ–¹å›¾
    hist_h = cv2.calcHist([hsv], [0], None, [50], [0, 180])
    hist_s = cv2.calcHist([hsv], [1], None, [50], [0, 256])
    hist_v = cv2.calcHist([hsv], [2], None, [50], [0, 256])
    
    # å½’ä¸€åŒ–å¹¶è¿æ¥ç‰¹å¾
    hist_h = hist_h.flatten() / hist_h.sum()
    hist_s = hist_s.flatten() / hist_s.sum()
    hist_v = hist_v.flatten() / hist_v.sum()
    
    feature = np.concatenate([hist_h, hist_s, hist_v])
    return feature

if __name__ == "__main__":
    debug_video_segmentation() 